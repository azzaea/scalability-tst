[2019-06-30 23:21:38,45] [info] Running with database db.url = jdbc:hsqldb:mem:99c3af16-1b11-4968-829b-bda8f40809ea;shutdown=false;hsqldb.tx=mvcc
[2019-06-30 23:21:46,01] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000
[2019-06-30 23:21:46,03] [info] [RenameWorkflowOptionsInMetadata] 100%
[2019-06-30 23:21:46,11] [info] Running with database db.url = jdbc:hsqldb:mem:21eb1014-583c-418f-84fb-e2ea29b87014;shutdown=false;hsqldb.tx=mvcc
[2019-06-30 23:21:46,50] [info] Slf4jLogger started
[2019-06-30 23:21:46,86] [info] Workflow heartbeat configuration:
{
  "cromwellId" : "cromid-d30f75b",
  "heartbeatInterval" : "2 minutes",
  "ttl" : "10 minutes",
  "writeBatchSize" : 10000,
  "writeThreshold" : 10000
}
[2019-06-30 23:21:46,91] [info] Metadata summary refreshing every 2 seconds.
[2019-06-30 23:21:46,92] [[38;5;220mwarn[0m] 'docker.hash-lookup.gcr-api-queries-per-100-seconds' is being deprecated, use 'docker.hash-lookup.gcr.throttle' instead (see reference.conf)
[2019-06-30 23:21:46,93] [info] WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.
[2019-06-30 23:21:46,93] [info] CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.
[2019-06-30 23:21:46,93] [info] KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.
[2019-06-30 23:21:46,98] [info] JobExecutionTokenDispenser - Distribution rate: 5 per 1 seconds.
[2019-06-30 23:21:47,21] [info] SingleWorkflowRunnerActor: Version 39
[2019-06-30 23:21:47,22] [info] SingleWorkflowRunnerActor: Submitting workflow
[2019-06-30 23:21:47,27] [info] Unspecified type (Unspecified version) workflow 274c49a9-dc89-4bcd-ae75-f025125f1869 submitted
[2019-06-30 23:21:47,28] [info] SingleWorkflowRunnerActor: Workflow submitted [38;5;2m274c49a9-dc89-4bcd-ae75-f025125f1869[0m
[2019-06-30 23:21:47,28] [info] 1 new workflows fetched by cromid-d30f75b: 274c49a9-dc89-4bcd-ae75-f025125f1869
[2019-06-30 23:21:47,28] [info] WorkflowManagerActor Starting workflow [38;5;2m274c49a9-dc89-4bcd-ae75-f025125f1869[0m
[2019-06-30 23:21:47,29] [info] WorkflowManagerActor Successfully started WorkflowActor-274c49a9-dc89-4bcd-ae75-f025125f1869
[2019-06-30 23:21:47,29] [info] Retrieved 1 workflows from the WorkflowStoreActor
[2019-06-30 23:21:47,30] [info] WorkflowStoreHeartbeatWriteActor configured to flush with batch size 10000 and process rate 2 minutes.
[2019-06-30 23:21:47,37] [info] MaterializeWorkflowDescriptorActor [[38;5;2m274c49a9[0m]: Parsing workflow as WDL draft-2
[2019-06-30 23:21:47,94] [info] MaterializeWorkflowDescriptorActor [[38;5;2m274c49a9[0m]: Call-to-Backend assignments: hostwf.host1 -> slurm
[2019-06-30 23:21:52,00] [info] Not triggering log of token queue status. Effective log interval = None
[2019-06-30 23:21:52,44] [info] WorkflowExecutionActor-274c49a9-dc89-4bcd-ae75-f025125f1869 [[38;5;2m274c49a9[0m]: Starting hostwf.host1 (2 shards)
[2019-06-30 23:21:53,02] [info] Assigned new job execution tokens to the following groups: 274c49a9: 2
[2019-06-30 23:21:53,26] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2m274c49a9[0mhostwf.host1:0:1]: [38;5;5mhostname[0m
[2019-06-30 23:21:53,26] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2m274c49a9[0mhostwf.host1:1:1]: [38;5;5mhostname[0m
[2019-06-30 23:21:53,35] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2m274c49a9[0mhostwf.host1:0:1]: executing: sbatch -J cromwell_274c49a9_host1 -D /igbgroup/a-m/azzaea/scalability-tst/wdl/cromwell-executions/hostwf/274c49a9-dc89-4bcd-ae75-f025125f1869/call-host1/shard-0 -o /igbgroup/a-m/azzaea/scalability-tst/wdl/cromwell-executions/hostwf/274c49a9-dc89-4bcd-ae75-f025125f1869/call-host1/shard-0/execution/stdout -e /igbgroup/a-m/azzaea/scalability-tst/wdl/cromwell-executions/hostwf/274c49a9-dc89-4bcd-ae75-f025125f1869/call-host1/shard-0/execution/stderr -p normal -c 1 --wrap "/bin/bash /igbgroup/a-m/azzaea/scalability-tst/wdl/cromwell-executions/hostwf/274c49a9-dc89-4bcd-ae75-f025125f1869/call-host1/shard-0/execution/script"
[2019-06-30 23:21:53,35] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2m274c49a9[0mhostwf.host1:1:1]: executing: sbatch -J cromwell_274c49a9_host1 -D /igbgroup/a-m/azzaea/scalability-tst/wdl/cromwell-executions/hostwf/274c49a9-dc89-4bcd-ae75-f025125f1869/call-host1/shard-1 -o /igbgroup/a-m/azzaea/scalability-tst/wdl/cromwell-executions/hostwf/274c49a9-dc89-4bcd-ae75-f025125f1869/call-host1/shard-1/execution/stdout -e /igbgroup/a-m/azzaea/scalability-tst/wdl/cromwell-executions/hostwf/274c49a9-dc89-4bcd-ae75-f025125f1869/call-host1/shard-1/execution/stderr -p normal -c 1 --wrap "/bin/bash /igbgroup/a-m/azzaea/scalability-tst/wdl/cromwell-executions/hostwf/274c49a9-dc89-4bcd-ae75-f025125f1869/call-host1/shard-1/execution/script"
[2019-06-30 23:21:57,01] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2m274c49a9[0mhostwf.host1:0:1]: job id: 3501000
[2019-06-30 23:21:57,01] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2m274c49a9[0mhostwf.host1:1:1]: job id: 3501001
[2019-06-30 23:21:57,01] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2m274c49a9[0mhostwf.host1:1:1]: Cromwell will watch for an rc file but will *not* double-check whether this job is actually alive (unless Cromwell restarts)
[2019-06-30 23:21:57,01] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2m274c49a9[0mhostwf.host1:0:1]: Cromwell will watch for an rc file but will *not* double-check whether this job is actually alive (unless Cromwell restarts)
[2019-06-30 23:21:57,01] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2m274c49a9[0mhostwf.host1:1:1]: Status change from - to Running
[2019-06-30 23:21:57,01] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2m274c49a9[0mhostwf.host1:0:1]: Status change from - to Running
[2019-06-30 23:22:19,20] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2m274c49a9[0mhostwf.host1:1:1]: Status change from Running to Done
[2019-06-30 23:22:20,73] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2m274c49a9[0mhostwf.host1:0:1]: Status change from Running to Done
[2019-06-30 23:22:23,09] [info] WorkflowExecutionActor-274c49a9-dc89-4bcd-ae75-f025125f1869 [[38;5;2m274c49a9[0m]: Workflow hostwf complete. Final Outputs:
{
  "hostwf.logfile": "/tmp/5809526293794569882/write_lines_3641bc1a31b60fff741d83fc472dffa4.tmp"
}
[2019-06-30 23:22:23,14] [info] WorkflowManagerActor WorkflowActor-274c49a9-dc89-4bcd-ae75-f025125f1869 is in a terminal state: WorkflowSucceededState
[2019-06-30 23:22:40,76] [info] SingleWorkflowRunnerActor workflow finished with status 'Succeeded'.
{
  "outputs": {
    "hostwf.logfile": "/tmp/5809526293794569882/write_lines_3641bc1a31b60fff741d83fc472dffa4.tmp"
  },
  "id": "274c49a9-dc89-4bcd-ae75-f025125f1869"
}
[2019-06-30 23:22:42,03] [info] Workflow polling stopped
[2019-06-30 23:22:42,05] [info] Shutting down WorkflowStoreActor - Timeout = 5 seconds
[2019-06-30 23:22:42,05] [info] 0 workflows released by cromid-d30f75b
[2019-06-30 23:22:42,05] [info] Shutting down WorkflowLogCopyRouter - Timeout = 5 seconds
[2019-06-30 23:22:42,06] [info] Shutting down JobExecutionTokenDispenser - Timeout = 5 seconds
[2019-06-30 23:22:42,06] [info] JobExecutionTokenDispenser stopped
[2019-06-30 23:22:42,06] [info] Aborting all running workflows.
[2019-06-30 23:22:42,06] [info] WorkflowStoreActor stopped
[2019-06-30 23:22:42,07] [info] WorkflowLogCopyRouter stopped
[2019-06-30 23:22:42,07] [info] Shutting down WorkflowManagerActor - Timeout = 3600 seconds
[2019-06-30 23:22:42,07] [info] WorkflowManagerActor All workflows finished
[2019-06-30 23:22:42,07] [info] WorkflowManagerActor stopped
[2019-06-30 23:22:42,32] [info] Connection pools shut down
[2019-06-30 23:22:42,32] [info] Shutting down SubWorkflowStoreActor - Timeout = 1800 seconds
[2019-06-30 23:22:42,32] [info] Shutting down JobStoreActor - Timeout = 1800 seconds
[2019-06-30 23:22:42,32] [info] Shutting down CallCacheWriteActor - Timeout = 1800 seconds
[2019-06-30 23:22:42,32] [info] Shutting down ServiceRegistryActor - Timeout = 1800 seconds
[2019-06-30 23:22:42,32] [info] Shutting down DockerHashActor - Timeout = 1800 seconds
[2019-06-30 23:22:42,32] [info] Shutting down IoProxy - Timeout = 1800 seconds
[2019-06-30 23:22:42,32] [info] SubWorkflowStoreActor stopped
[2019-06-30 23:22:42,32] [info] CallCacheWriteActor Shutting down: 0 queued messages to process
[2019-06-30 23:22:42,32] [info] KvWriteActor Shutting down: 0 queued messages to process
[2019-06-30 23:22:42,32] [info] WriteMetadataActor Shutting down: 0 queued messages to process
[2019-06-30 23:22:42,32] [info] JobStoreActor stopped
[2019-06-30 23:22:42,32] [info] CallCacheWriteActor stopped
[2019-06-30 23:22:42,32] [info] IoProxy stopped
[2019-06-30 23:22:42,32] [info] ServiceRegistryActor stopped
[2019-06-30 23:22:42,33] [info] DockerHashActor stopped
[2019-06-30 23:22:42,33] [info] Database closed
[2019-06-30 23:22:42,33] [info] Stream materializer shut down
[2019-06-30 23:22:42,33] [info] WDL HTTP import resolver closed
